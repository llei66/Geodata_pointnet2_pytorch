{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import panel as pn\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "import glob\n",
    "from matplotlib.colors import ListedColormap\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "pn.extension('vtk')\n",
    "os.system('/usr/bin/Xvfb :99 -screen 0 1024x768x24 &')\n",
    "os.environ['DISPLAY'] = ':99'\n",
    "os.environ['PYVISTA_OFF_SCREEN'] = 'True'\n",
    "os.environ['PYVISTA_USE_PANEL'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load geodata\n",
    "DIR = os.path.dirname(os.getcwd())\n",
    "dataset_options = OmegaConf.load(os.path.join(DIR,'conf/data/segmentation/geodata.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_options.data.dataroot = os.path.join(DIR,\"data\")\n",
    "dataset = S3DISFusedDataset(dataset_options.data)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## init training\n",
    "#from torch_points3d.trainer import Trainer\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import hydra\n",
    "import time\n",
    "import logging\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "\n",
    "# Import building function for model and dataset\n",
    "from torch_points3d.datasets.dataset_factory import instantiate_dataset\n",
    "from torch_points3d.models.model_factory import instantiate_model\n",
    "\n",
    "# Import BaseModel / BaseDataset for type checking\n",
    "from torch_points3d.models.base_model import BaseModel\n",
    "from torch_points3d.datasets.base_dataset import BaseDataset\n",
    "\n",
    "# Import from metrics\n",
    "from torch_points3d.metrics.base_tracker import BaseTracker\n",
    "from torch_points3d.metrics.colored_tqdm import Coloredtqdm as Ctq\n",
    "from torch_points3d.metrics.model_checkpoint import ModelCheckpoint\n",
    "\n",
    "# Utils import\n",
    "from torch_points3d.utils.colors import COLORS\n",
    "from torch_points3d.utils.wandb_utils import Wandb\n",
    "from torch_points3d.visualization import Visualizer\n",
    "log = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define train class\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"\n",
    "    TorchPoints3d Trainer handles the logic between\n",
    "        - BaseModel,\n",
    "        - Dataset and its Tracker\n",
    "        - A custom ModelCheckpoint\n",
    "        - A custom Visualizer\n",
    "    It supports MC dropout - multiple voting_runs for val / test datasets\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        self._cfg = cfg\n",
    "        self._initialize_trainer()\n",
    "\n",
    "    def _initialize_trainer(self):\n",
    "        # Enable CUDNN BACKEND\n",
    "        torch.backends.cudnn.enabled = self.enable_cudnn\n",
    "        if not self.has_training:\n",
    "            resume = False\n",
    "            self._cfg.training = self._cfg\n",
    "        else:\n",
    "            resume = bool(self._cfg.training.checkpoint_dir)\n",
    "\n",
    "        # Get device\n",
    "        if self._cfg.training.cuda > -1 and torch.cuda.is_available():\n",
    "            device = \"cuda\"\n",
    "            torch.cuda.set_device(self._cfg.training.cuda)\n",
    "        else:\n",
    "            device = \"cpu\"\n",
    "        self._device = torch.device(device)\n",
    "        log.info(\"DEVICE : {}\".format(self._device))\n",
    "\n",
    "        # Profiling\n",
    "        if self.profiling:\n",
    "            # Set the num_workers as torch.utils.bottleneck doesn't work well with it\n",
    "            self._cfg.training.num_workers = 0\n",
    "\n",
    "        # Start Wandb if public\n",
    "        if self.wandb_log:\n",
    "            Wandb.launch(self._cfg, self._cfg.wandb.public and self.wandb_log)\n",
    "\n",
    "        # Checkpoint\n",
    "        self._checkpoint: ModelCheckpoint = ModelCheckpoint(\n",
    "            self._cfg.training.checkpoint_dir,\n",
    "            self._cfg.model_name,\n",
    "            self._cfg.training.weight_name,\n",
    "            run_config=self._cfg,\n",
    "            resume=resume,\n",
    "        )\n",
    "\n",
    "        # Create model and datasets\n",
    "        if not self._checkpoint.is_empty:\n",
    "            self._dataset: BaseDataset = instantiate_dataset(self._checkpoint.data_config)\n",
    "            self._model: BaseModel = self._checkpoint.create_model(\n",
    "                self._dataset, weight_name=self._cfg.training.weight_name\n",
    "            )\n",
    "        else:\n",
    "            self._dataset: BaseDataset = instantiate_dataset(self._cfg.data)\n",
    "            self._model: BaseModel = instantiate_model(copy.deepcopy(self._cfg), self._dataset)\n",
    "            self._model.instantiate_optimizers(self._cfg)\n",
    "            self._model.set_pretrained_weights()\n",
    "            if not self._checkpoint.validate(self._dataset.used_properties):\n",
    "                log.warning(\n",
    "                    \"The model will not be able to be used from pretrained weights without the corresponding dataset. Current properties are {}\".format(\n",
    "                        self._dataset.used_properties\n",
    "                    )\n",
    "                )\n",
    "        self._checkpoint.dataset_properties = self._dataset.used_properties\n",
    "\n",
    "        log.info(self._model)\n",
    "\n",
    "        self._model.log_optimizers()\n",
    "        log.info(\"Model size = %i\", sum(param.numel() for param in self._model.parameters() if param.requires_grad))\n",
    "\n",
    "        # Set dataloaders\n",
    "        self._dataset.create_dataloaders(\n",
    "            self._model,\n",
    "            self._cfg.training.batch_size,\n",
    "            self._cfg.training.shuffle,\n",
    "            self._cfg.training.num_workers,\n",
    "            self.precompute_multi_scale,\n",
    "        )\n",
    "        log.info(self._dataset)\n",
    "\n",
    "        # Verify attributes in dataset\n",
    "        self._model.verify_data(self._dataset.train_dataset[0])\n",
    "\n",
    "        # Choose selection stage\n",
    "        selection_stage = getattr(self._cfg, \"selection_stage\", \"\")\n",
    "        self._checkpoint.selection_stage = self._dataset.resolve_saving_stage(selection_stage)\n",
    "        self._tracker: BaseTracker = self._dataset.get_tracker(self.wandb_log, self.tensorboard_log)\n",
    "\n",
    "        if self.wandb_log:\n",
    "            Wandb.launch(self._cfg, not self._cfg.wandb.public and self.wandb_log)\n",
    "\n",
    "        # Run training / evaluation\n",
    "        self._model = self._model.to(self._device)\n",
    "        if self.has_visualization:\n",
    "            self._visualizer = Visualizer(\n",
    "                self._cfg.visualization, self._dataset.num_batches, self._dataset.batch_size, os.getcwd()\n",
    "            )\n",
    "\n",
    "    def train(self):\n",
    "        self._is_training = True\n",
    "\n",
    "        for epoch in range(self._checkpoint.start_epoch, self._cfg.training.epochs):\n",
    "            log.info(\"EPOCH %i / %i\", epoch, self._cfg.training.epochs)\n",
    "\n",
    "            self._train_epoch(epoch)\n",
    "\n",
    "            if self.profiling:\n",
    "                return 0\n",
    "\n",
    "            if epoch % self.eval_frequency != 0:\n",
    "                continue\n",
    "\n",
    "            if self._dataset.has_val_loader:\n",
    "                self._test_epoch(epoch, \"val\")\n",
    "\n",
    "            if self._dataset.has_test_loaders:\n",
    "                self._test_epoch(epoch, \"test\")\n",
    "\n",
    "        # Single test evaluation in resume case\n",
    "        if self._checkpoint.start_epoch > self._cfg.training.epochs:\n",
    "            if self._dataset.has_test_loaders:\n",
    "                self._test_epoch(epoch, \"test\")\n",
    "\n",
    "    def eval(self, stage_name=\"\"):\n",
    "        self._is_training = False\n",
    "\n",
    "        epoch = self._checkpoint.start_epoch\n",
    "        if self._dataset.has_val_loader:\n",
    "            if not stage_name or stage_name == \"val\":\n",
    "                self._test_epoch(epoch, \"val\")\n",
    "\n",
    "        if self._dataset.has_test_loaders:\n",
    "            if not stage_name or stage_name == \"test\":\n",
    "                self._test_epoch(epoch, \"test\")\n",
    "\n",
    "    def _finalize_epoch(self, epoch):\n",
    "        self._tracker.finalise(**self.tracker_options)\n",
    "        if self._is_training:\n",
    "            metrics = self._tracker.publish(epoch)\n",
    "            self._checkpoint.save_best_models_under_current_metrics(self._model, metrics, self._tracker.metric_func)\n",
    "            if self.wandb_log and self._cfg.wandb.public:\n",
    "                Wandb.add_file(self._checkpoint.checkpoint_path)\n",
    "            if self._tracker._stage == \"train\":\n",
    "                log.info(\"Learning rate = %f\" % self._model.learning_rate)\n",
    "\n",
    "    def _train_epoch(self, epoch: int):\n",
    "\n",
    "        self._model.train()\n",
    "        self._tracker.reset(\"train\")\n",
    "        self._visualizer.reset(epoch, \"train\")\n",
    "        train_loader = self._dataset.train_dataloader\n",
    "\n",
    "        iter_data_time = time.time()\n",
    "        with Ctq(train_loader) as tq_train_loader:\n",
    "            for i, data in enumerate(tq_train_loader):\n",
    "                t_data = time.time() - iter_data_time\n",
    "                iter_start_time = time.time()\n",
    "                self._model.set_input(data, self._device)\n",
    "                self._model.optimize_parameters(epoch, self._dataset.batch_size)\n",
    "                if i % 10 == 0:\n",
    "                    with torch.no_grad():\n",
    "                        self._tracker.track(self._model, data=data, **self.tracker_options)\n",
    "\n",
    "                tq_train_loader.set_postfix(\n",
    "                    **self._tracker.get_metrics(),\n",
    "                    data_loading=float(t_data),\n",
    "                    iteration=float(time.time() - iter_start_time),\n",
    "                    color=COLORS.TRAIN_COLOR\n",
    "                )\n",
    "\n",
    "                if self._visualizer.is_active:\n",
    "                    self._visualizer.save_visuals(self._model.get_current_visuals())\n",
    "\n",
    "                iter_data_time = time.time()\n",
    "\n",
    "                if self.early_break:\n",
    "                    break\n",
    "\n",
    "                if self.profiling:\n",
    "                    if i > self.num_batches:\n",
    "                        return 0\n",
    "\n",
    "        self._finalize_epoch(epoch)\n",
    "\n",
    "    def _test_epoch(self, epoch, stage_name: str):\n",
    "        voting_runs = self._cfg.get(\"voting_runs\", 1)\n",
    "        if stage_name == \"test\":\n",
    "            loaders = self._dataset.test_dataloaders\n",
    "        else:\n",
    "            loaders = [self._dataset.val_dataloader]\n",
    "\n",
    "        self._model.eval()\n",
    "        if self.enable_dropout:\n",
    "            self._model.enable_dropout_in_eval()\n",
    "\n",
    "        for loader in loaders:\n",
    "            stage_name = loader.dataset.name\n",
    "            self._tracker.reset(stage_name)\n",
    "            if self.has_visualization:\n",
    "                self._visualizer.reset(epoch, stage_name)\n",
    "            if not self._dataset.has_labels(stage_name) and not self.tracker_options.get(\n",
    "                \"make_submission\", False\n",
    "            ):  # No label, no submission -> do nothing\n",
    "                log.warning(\"No forward will be run on dataset %s.\" % stage_name)\n",
    "                continue\n",
    "\n",
    "            for i in range(voting_runs):\n",
    "                with Ctq(loader) as tq_loader:\n",
    "                    for data in tq_loader:\n",
    "                        with torch.no_grad():\n",
    "                            self._model.set_input(data, self._device)\n",
    "                            self._model.forward(epoch=epoch)\n",
    "                            self._tracker.track(self._model, data=data, **self.tracker_options)\n",
    "                        tq_loader.set_postfix(**self._tracker.get_metrics(), color=COLORS.TEST_COLOR)\n",
    "\n",
    "                        if self.has_visualization and self._visualizer.is_active:\n",
    "                            self._visualizer.save_visuals(self._model.get_current_visuals())\n",
    "\n",
    "                        if self.early_break:\n",
    "                            break\n",
    "\n",
    "                        if self.profiling:\n",
    "                            if i > self.num_batches:\n",
    "                                return 0\n",
    "\n",
    "            self._finalize_epoch(epoch)\n",
    "            self._tracker.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our train paramter\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
